{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa13f7-57bf-453b-bee8-ca9e7cd268d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import retinapy\n",
    "import retinapy.spikeprediction as sp\n",
    "import retinapy.mea as mea\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as subplots\n",
    "from collections import defaultdict\n",
    "import retinapy.spikedistancefield as sdf\n",
    "import torch.nn as nn\n",
    "import retinapy.nn\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import pathlib\n",
    "from collections import namedtuple\n",
    "import logging\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4646b-c560-4f6a-9b4e-7d100daa19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookLogger:\n",
    "    def info(self, msg):\n",
    "        print(msg)\n",
    "    def error(self, msg):\n",
    "        print(msg)\n",
    "    def warn(self, msg):\n",
    "        print(msg)\n",
    "    def warning(self, msg):\n",
    "        print(msg)\n",
    "_logger = NotebookLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8057f6-05e1-49b3-90ed-f69f56a70001",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_pattern_path = \"../data/ff_noise.h5\"\n",
    "stimulus_rec_path = \"../data/ff_recorded_noise.pickle\"\n",
    "response_path = \"../data/ff_spike_response.pickle\"\n",
    "rec_name = \"Chicken_17_08_21_Phase_00\"\n",
    "\n",
    "rec = mea.single_3brain_recording(\n",
    "    rec_name,\n",
    "    mea.load_stimulus_pattern(stimulus_pattern_path),\n",
    "    mea.load_recorded_stimulus(stimulus_rec_path),\n",
    "    mea.load_response(response_path),\n",
    "    include_clusters={21},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7252f5d-bd41-44b4-817c-a29206662d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"../out/exp/1/7/0/DistFieldCnn-9ds_3174in/checkpoint_best_loss_epoch-78.pth\"\n",
    "model_ckpt = \"../out/exp/1/10/13/DistFieldCnn-9ds_3174in/checkpoint_best_loss_epoch-99.pth\"\n",
    "assert pathlib.Path(model_ckpt).resolve().exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d8094-5f28-43bb-b9bf-2c835b805a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distfield model\n",
    "input_len = 3174\n",
    "output_len = 398\n",
    "downsample = 9\n",
    "df_trainable = sp.DistFieldCnnTrainableGroup.create_trainable(rec, sp.Configuration(downsample, input_len, output_len))\n",
    "retinapy.models.load_model(df_trainable.model, model_ckpt)\n",
    "retinapy.dataset.SpikeDistanceFieldDataset.DROP_RATE = 0\n",
    "df_trainable.model.eval()\n",
    "df_trainable.model.cuda()\n",
    "\n",
    "# Count prediction model.\n",
    "class DistFieldToSpikeCount(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistFieldToSpikeCount, self).__init__()\n",
    "        self.act = nn.Softplus()\n",
    "        k = 5\n",
    "        n = 9\n",
    "        c = [25, 50, 50,\n",
    "             50, 50, 100,\n",
    "             100, 200, 200]\n",
    "        assert len(c) == n\n",
    "        expansion = 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            retinapy.nn.Residual1dBlock(\n",
    "                1, c[0]*expansion, c[0], kernel_size=k, downsample=True\n",
    "            ),\n",
    "            *[\n",
    "                retinapy.nn.Residual1dBlock(\n",
    "                    c[i-1],\n",
    "                    c[i]*expansion,\n",
    "                    c[i],\n",
    "                    kernel_size=k,\n",
    "                    downsample=True,\n",
    "                )\n",
    "                for i in range(1, n)\n",
    "            ],\n",
    "        )\n",
    "        self.layer2 = nn.Linear(in_features=c[-1], out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(torch.flatten(x, start_dim=1))\n",
    "        x = self.act(x)\n",
    "        x = torch.flatten(x) # shape: [batch,]\n",
    "        return x\n",
    "    \n",
    "class SpikeCountTrainable:\n",
    "    def __init__(self, distfield_trainable, model, pred_len):\n",
    "        self.df_trainable = distfield_trainable\n",
    "        self.train_ds = df_trainable.train_ds\n",
    "        self.val_ds = df_trainable.val_ds\n",
    "        self.test_ds = df_trainable.test_ds  \n",
    "        self.model = model\n",
    "        self.pred_start = 100\n",
    "        self.pred_len = pred_len # 10ms\n",
    "        #self.loss_fn = nn.MSELoss()\n",
    "        self.loss_fn = torch.nn.PoissonNLLLoss(log_input=False)\n",
    "        self.ave_count = (10 / 1000) * 10 # 10 per second, counted in bins of 10ms\n",
    "        self.sd = 0.2 # TODO\n",
    "        \n",
    "    def spikes_to_y(self, spikes):\n",
    "        start = self.pred_start\n",
    "        end = start + self.pred_len\n",
    "        y = torch.sum(spikes[:,start:end], dim=1)\n",
    "        return y\n",
    "    \n",
    "    def forward(self, sample):\n",
    "        _, spikes, _ = sample\n",
    "        spikes = spikes.float().cuda()\n",
    "        with torch.no_grad():\n",
    "            df_model_out, _ = self.df_trainable.forward(sample)\n",
    "        model_in = df_model_out - 1.5 # The mean was about 1.5\n",
    "        model_out = self.model(model_in)\n",
    "        y = self.spikes_to_y(spikes)\n",
    "        target = self.y_to_nn_output(y)\n",
    "        loss = self.loss_fn(model_out, target=target)\n",
    "        acc = torch.mean((y == torch.round(self.nn_output_to_y(model_out))).float())\n",
    "        metrics = [retinapy._logging.Metric(\"accuracy\", acc)]\n",
    "        return model_out, loss, metrics\n",
    "    \n",
    "    def nn_output_to_y(self, nn_out):\n",
    "        \"\"\"Denormalize\"\"\"\n",
    "        return nn_out\n",
    "    \n",
    "    def y_to_nn_output(self, y):\n",
    "        return y\n",
    "    \n",
    "    def model_label(self):\n",
    "        return f\"DistFieldToSpikeCount-9ds_3174in_{self.pred_len}bins\"\n",
    "    \n",
    "    def evaluate(self, val_dl):\n",
    "        loss_meter = retinapy._logging.Meter(\"loss\")\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for (snippet, spikes, dist) in val_dl:\n",
    "            spikes = spikes.cuda()\n",
    "            gpu_sample = (snippet.cuda(), spikes, dist.cuda())\n",
    "            model_out, loss, _ = self.forward(gpu_sample)\n",
    "            batch_len = spikes.shape[0]\n",
    "            loss_meter.update(loss.item(), batch_len)\n",
    "            pred = self.nn_output_to_y(torch.round(model_out))\n",
    "            y = self.spikes_to_y(spikes)\n",
    "            predictions.append(pred)\n",
    "            targets.append(y)\n",
    "        p = torch.cat(predictions)\n",
    "        t = torch.cat(targets)\n",
    "        acc = (p == t).float().mean().item()\n",
    "        pearson_corr = scipy.stats.pearsonr(p.cpu(), t.cpu())[0]\n",
    "        metrics = [\n",
    "            retinapy._logging.Metric(\"loss\", loss_meter.avg),\n",
    "            retinapy._logging.Metric(\"accuracy\", acc),\n",
    "            retinapy._logging.Metric(\"pearson_corr\", pearson_corr)\n",
    "        ]\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ab726-a57a-49f6-8fe1-eff0c6035082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_ds, val_ds, test_ds):\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=opt.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=20,\n",
    "    )\n",
    "    val_dl = torch.utils.data.DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=opt.batch_size,\n",
    "        # For debugging, it's nice to see a variety:\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=20,\n",
    "    )\n",
    "    test_dl = torch.utils.data.DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=opt.batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=20,\n",
    "    )\n",
    "    return train_dl, val_dl, test_dl\n",
    "\n",
    "@contextmanager\n",
    "def evaluating(model):\n",
    "    \"\"\"\n",
    "    Context manager to set the model to eval mode and then back to train mode.\n",
    "\n",
    "    This is used just in case there is an caught exception that leads to\n",
    "    unexpected training state.\n",
    "    \"\"\"\n",
    "    original_mode = model.training\n",
    "    model.eval()\n",
    "    try:\n",
    "        model.eval()\n",
    "        yield\n",
    "    finally:\n",
    "        # Switch back to the original training mode.\n",
    "        model.train(original_mode)\n",
    "        \n",
    "def train(trainable, out_dir):\n",
    "    logging.info(f\"Training {trainable.model_label}\")\n",
    "    # Setup output (logging & checkpoints).\n",
    "    tensorboard_dir = out_dir / \"tensorboard\"\n",
    "    tb_logger = retinapy._logging.TbLogger(tensorboard_dir)\n",
    "\n",
    "    # Load the model & loss fn.\n",
    "    model = trainable.model\n",
    "\n",
    "    # Load the data.\n",
    "    train_dl, val_dl, test_dl = create_dataloaders(\n",
    "        trainable.train_ds, trainable.val_ds, trainable.test_ds\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=opt.lr, weight_decay=opt.weight_decay\n",
    "    )\n",
    "\n",
    "    model_saver = retinapy._logging.ModelSaver(out_dir, model, optimizer)\n",
    "    num_epochs = opt.epochs\n",
    "    step = 0\n",
    "    # Baseline.\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_meter = retinapy._logging.Meter(\"loss\")\n",
    "        for sample in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            model_out, total_loss, other_metrics = trainable.forward(sample)\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_size = len(sample[0])\n",
    "            loss_meter.update(total_loss.item(), batch_size)\n",
    "            metrics = [\n",
    "                retinapy._logging.Metric(\"loss\", total_loss.item()/batch_size),\n",
    "            ]\n",
    "            if other_metrics:\n",
    "                metrics.extend(other_metrics)\n",
    "            tb_logger.log(step, metrics, log_group=\"train\")\n",
    "\n",
    "            if step % opt.log_interval == 0:\n",
    "                model_mean = torch.mean(model_out)\n",
    "                model_sd = torch.std(model_out)\n",
    "                _logger.info(\n",
    "                    f\"epoch: {epoch}/{num_epochs} | \"\n",
    "                    f\"step: {step}/{len(train_dl)*num_epochs} | \"\n",
    "                    f\"loss: {loss_meter.avg:.5f} | \"\n",
    "                    f\"out mean (sd) : {model_mean:.5f} ({model_sd:.5f})\"\n",
    "                )\n",
    "                loss_meter.reset()\n",
    "            step += 1\n",
    "        # Evaluate and save at end of epoch.\n",
    "        _logger.info(\"Running epoch evaluation (val ds)\")\n",
    "        with evaluating(model), torch.no_grad():\n",
    "            metrics = trainable.evaluate(val_dl)\n",
    "            tb_logger.log(step, metrics, \"val-ds\")\n",
    "            retinapy._logging.print_metrics(metrics)\n",
    "        model_saver.save_checkpoint(epoch, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee9373-eeb4-4485-86ad-1aa64f1fe5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len=50\n",
    "trainable = SpikeCountTrainable(df_trainable, DistFieldToSpikeCount(), pred_len=pred_len)\n",
    "#retinapy.models.load_model(trainable.model, ms100_model_ckpt)\n",
    "Opt = namedtuple('Opt', \"log_interval, lr, weight_decay, epochs, batch_size\")\n",
    "opt = Opt(log_interval=1000, weight_decay=1e-5, lr=1e-4, epochs=5, batch_size=128)\n",
    "out_dir = retinapy._logging.get_outdir(pathlib.Path('../out/'), labels=['exp', '1', '10', f'pred{pred_len}', trainable.model_label()])\n",
    "train(trainable, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37edd1-1a63-41c9-83b7-8d21e1609fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_on_test_ds(trainable, quick=True):\n",
    "    trainable.model.eval()\n",
    "    targets = []\n",
    "    test_ds = trainable.test_ds\n",
    "    predictions = []\n",
    "    start = trainable.pred_start\n",
    "    eval_len = trainable.pred_len\n",
    "    until = len(test_ds)//5 if quick else len(test_ds)\n",
    "    for t in range(0, until, eval_len):\n",
    "        snippet, spikes, dist = test_ds[t]\n",
    "        snippet = torch.unsqueeze(torch.Tensor(snippet), 0)\n",
    "        spikes = torch.unsqueeze(torch.Tensor(spikes), 0)\n",
    "        dist = torch.unsqueeze(torch.Tensor(dist), 0)\n",
    "        pred = trainable.forward((snippet, spikes, dist))\n",
    "        num_spikes = torch.sum(spikes[0,start:start+eval_len])\n",
    "        predictions.append(pred[0].item())\n",
    "        targets.append(num_spikes)\n",
    "    p = torch.Tensor(predictions)\n",
    "    t = torch.Tensor(targets)\n",
    "    pearson_corr = scipy.stats.pearsonr(p.cpu(), t.cpu())[0]\n",
    "    acc = (torch.round(p) == t).float().mean().item()\n",
    "    print(f'acc: {acc}, pearson_corr: {pearson_corr}')\n",
    "    return t, p\n",
    "\n",
    "\n",
    "def display_results(t, p, step, chart_type=\"line\"): \n",
    "    acc = torch.mean((torch.round(p) == t).float())\n",
    "    pearson_corr = scipy.stats.pearsonr(p, t)[0]\n",
    "    print(f\"accuracy: {acc}, pearson_corr: {pearson_corr}\")\n",
    "    plot_w = 200\n",
    "    num_plots = max(len(t) // plot_w, 1)\n",
    "    fig = subplots.make_subplots(rows=num_plots, cols=1, shared_xaxes=True, vertical_spacing=0.015)\n",
    "    for i in range(0, num_plots):\n",
    "        xs = np.arange(0, plot_w) * step\n",
    "        start, end = np.array([i, i+1]) * plot_w\n",
    "        if chart_type not in {\"dot\", \"line\"}:\n",
    "            raise ValueError(f\"Only dot and line charts are supported. Got ({chart_type}).\")\n",
    "        mode = 'markers' if chart_type=='dot' else 'lines'\n",
    "        marker_size = 4\n",
    "        chart_spike = go.Scatter(x=xs, y=t[start:end], name=\"spikes\", \n",
    "                                   line_color='red', mode=mode, marker={'size':marker_size},\n",
    "                                   legendgroup='g1', showlegend=(i==0))\n",
    "        chart_pred = go.Scatter(x=xs, y=p[start:end], name=\"pred\",\n",
    "                                  line_color='darkblue', mode=mode, marker={'size':marker_size},\n",
    "                                  legendgroup='g2', showlegend=(i==0))\n",
    "        fig.add_trace(chart_spike, row=i+1, col=1)\n",
    "        fig.add_trace(chart_pred, row=i+1, col=1)\n",
    "    fig.update_layout({\n",
    "            \"margin\":{\"l\":0, \"r\":0, \"t\":80, \"b\":10, \"pad\":10},\n",
    "            \"autosize\":True,\n",
    "            \"height\":65*num_plots,\n",
    "            \"width\":800,\n",
    "            \"yaxis_range\":[0,2],\n",
    "            \"yaxis_fixedrange\":True,\n",
    "            \"title\":f\"Real spikes vs. predicted spikes (with another neural-net) in {step/2}ms bins<br><span style='font-size:90%'>(acc: {acc:.3f}, corr: {pearson_corr:.3f})</span>\",\n",
    "            \"title_x\":0.5,\n",
    "            \"title_pad\":dict(l=1, r=1, b=20, t=20),\n",
    "            \"xaxis\":{'title':f'time (ms), {step/2} bins', 'side':'bottom'},\n",
    "            \"yaxis\":{'title':'num. spikes', 'tickvals':[0, 1, 2],} })\n",
    "    fig.update_yaxes(range=[0,2], tickvals=[0,1,2])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e77a65-f7e5-44b3-8ace-362445155bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainable = SpikeCountTrainable(df_trainable, DistFieldToSpikeCount(), pred_len=20)\n",
    "#retinapy.models.load_model(trainable.model, ms10_model_ckpt)\n",
    "trainable.model.cuda()\n",
    "targets, predictions = run_model_on_test_ds(trainable, quick=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d022f-bb6f-4e8e-a645-cddaae096f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = display_results(torch.Tensor(targets), torch.Tensor(predictions), step=trainable.pred_len, chart_type=\"line\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d193cff-5f7e-4e03-9f0c-9bb4751fb272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
