{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a5f619-4ef6-4e00-a6d0-1476e9913259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import retinapy\n",
    "import retinapy.spikeprediction as sp\n",
    "import retinapy.mea as mea\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as subplots\n",
    "from collections import defaultdict\n",
    "import retinapy.spikedistancefield as sdf\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import pathlib\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import math\n",
    "import pandas as pd\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18aff36-4661-40f4-8c51-7a052ca1d5d9",
   "metadata": {},
   "source": [
    "## Figures and stats, some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0959c1-bc13-40df-84ca-f58e741ded23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_plot(kernel, kernel_pad, bin_duration_ms):\n",
    "    colormap = pd.DataFrame({\n",
    "        'names':['Red', 'Green', 'UV', 'Blue', 'Stim'],\n",
    "        'display_hex':['#ff0a0a', '#0aff0a', '#0a0aff', '#303030', '#0a0a0a']})\n",
    "    fig = go.Figure()\n",
    "    xs = (np.arange(kernel.shape[0]) - kernel.shape[0] + kernel_pad) * bin_duration_ms\n",
    "    #fig.add_vline(x=-100, line_width=2, line_dash='dot', line_color='grey',\n",
    "    #              annotation_text='-100ms', annotation_position='bottom right')\n",
    "    for c in range(4):\n",
    "        fig.add_trace(go.Scatter(x=xs, \n",
    "                                 y=kernel[:,c], \n",
    "                                 line_color=colormap.loc[c]['display_hex'], \n",
    "                                 mode='lines'))\n",
    "    fig.update_layout(autosize=False,\n",
    "                      height=400,\n",
    "                      width=800,\n",
    "                      margin=dict(l=1, r=1, b=1, t=25, pad=10),\n",
    "                      yaxis_fixedrange=True,\n",
    "                      showlegend=False,\n",
    "                      title='Kernel',\n",
    "                      title_x=0.5,\n",
    "                      title_pad=dict(l=1, r=1, b=10, t=10),\n",
    "                      xaxis={'title':'time (ms), with spike at 0'},\n",
    "                      yaxis={'title':'Stimulus', 'range': [0,1]} )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03ad475-7938-4970-8b09-ebeedc929a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(pred, actual):\n",
    "    p,y  = pred, actual\n",
    "    pearson_corr = scipy.stats.pearsonr(p, y)[0]\n",
    "    pr = np.round(p)\n",
    "    acc = np.mean(pr == y)\n",
    "    cm = sklearn.metrics.confusion_matrix(y, pr)\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    acc_2 = (TP + TN) / (TP + TN + FN + FP)\n",
    "    assert acc_2 == acc\n",
    "    recall = TP / (TP + FN)    # Out of all true 1s, how many are predicted as 1?\n",
    "    precision = TP / (TP + FP) # Given a 1 prediction, what is the chance that it was a 1?\n",
    "    print(f'pred 1s: {TP+FP}, actual 1s: {TP+FN}')\n",
    "    print(f'acc: {acc:.4f}, pearson_corr: {pearson_corr:.4f}, '\n",
    "          f'recall: {recall:.4f}, precision: {precision:.4f}')\n",
    "    print(f'sklearn report:\\n{sklearn.metrics.classification_report(y, pr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac7aa6b-7f64-4cb5-b864-31f2be20fde4",
   "metadata": {},
   "source": [
    "## Load data and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0974a3e0-5b59-4566-b8ff-7b4525be336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_pattern_path = \"../data/ff_noise.h5\"\n",
    "stimulus_rec_path = \"../data/ff_recorded_noise.pickle\"\n",
    "response_path = \"../data/ff_spike_response.pickle\"\n",
    "rec_name = \"Chicken_17_08_21_Phase_00\"\n",
    "\n",
    "rec = mea.single_3brain_recording(\n",
    "    rec_name,\n",
    "    mea.load_stimulus_pattern(stimulus_pattern_path),\n",
    "    mea.load_recorded_stimulus(stimulus_rec_path),\n",
    "    mea.load_response(response_path),\n",
    "    include_clusters={21},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e52cfe-f27f-4e63-ad40-69168b340529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"../out/exp/1/10/13/DistFieldCnn-9ds_3174in/checkpoint_epoch-99.pth\"\n",
    "model_ckpt = \"../out/exp/1/1/3/double_l1/2/DistFieldCnn-9ds_3174in/checkpoint_best_loss.pth\"\n",
    "assert pathlib.Path(model_ckpt).resolve().exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17018f12-3704-4b30-9c6c-feca1290b0fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m downsample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m\n\u001b[1;32m      5\u001b[0m trainable \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mDistFieldCnnTGroup\u001b[38;5;241m.\u001b[39mcreate_trainable([rec], sp\u001b[38;5;241m.\u001b[39mConfiguration(downsample, input_len, output_len))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mretinapy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m trainable\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      8\u001b[0m trainable\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/app/retinapy/src/retinapy/models.py:27\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model, checkpoint_path, map_location)\u001b[0m\n\u001b[1;32m     24\u001b[0m     checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(checkpoint_path\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     26\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model from (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m checkpoint_state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m model_state \u001b[38;5;241m=\u001b[39m checkpoint_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(model_state)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/serialization.py:1049\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1049\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/serialization.py:1019\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1018\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1019\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39m_UntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# Create datasets and model.\n",
    "input_len = 3174\n",
    "output_len = 400 # 398...hmm\n",
    "downsample = 9\n",
    "trainable = sp.DistFieldCnnTGroup.create_trainable([rec], sp.Configuration(downsample, input_len, output_len))\n",
    "retinapy.models.load_model(trainable.model, model_ckpt)\n",
    "trainable.model.eval()\n",
    "trainable.model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6acc85-b9ef-46c7-80ec-ab4f0b9d6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_shape = trainable.test_ds[0][0].T.shape\n",
    "snippet_len = snippet_shape[0]\n",
    "print(f'Snippet shape: {snippet_shape}, input_len: {input_len}, output_len: {output_len}')\n",
    "assert snippet_shape[0] == (input_len + output_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5c698-540d-40e0-8592-8ee9c2d8d028",
   "metadata": {},
   "source": [
    "## 1. Kernel via STA approach\n",
    "The traditional STA approach to calculate kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f1666-c745-405c-890c-ac0a1f2c9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " |---stimulus-----------|\n",
    " |-------------|-target-|\n",
    " |-------------|--400---|\n",
    " |-------------|-|pred|-|\n",
    "0|         3174| |    | |\n",
    "                 3    3  \n",
    "                 2    4\n",
    "                 7    7\n",
    "                 4    4\n",
    "\n",
    "\"\"\"\n",
    "def whole_distfield(trainable, pred_len=200, pred_start=100, snippet_pad=600):\n",
    "    with torch.no_grad():\n",
    "        num_overlap = 2\n",
    "        assert pred_len % num_overlap == 0\n",
    "        step = pred_len // num_overlap\n",
    "        _slice = (pred_start, pred_start + pred_len)\n",
    "        summed = torch.zeros(size=(len(trainable.test_ds)+pred_len,), device='cpu')\n",
    "        for i in range(0, len(trainable.test_ds), step):\n",
    "            sample = trainable.test_ds[i]\n",
    "            assert len(sample) == 3\n",
    "            torch_sample = tuple(\n",
    "                torch.unsqueeze(torch.Tensor(e).float().cuda(), 0) for e in sample)\n",
    "            model_out, _ = trainable.forward(torch_sample)\n",
    "            summed[i:i+pred_len] = model_out[0,pred_start:pred_start + pred_len].cpu()\n",
    "        summed /= num_overlap\n",
    "    # Urh. There is a prefix due to spike prediction happening after the 3174 bins that\n",
    "    # are used for the input. Add in the offset for the fact that we are not taking the\n",
    "    # whole model output, but a slice starting at pred_start. \n",
    "    prefix_len = trainable.test_ds.mask_slice.start + pred_start - 1\n",
    "    suffix_len = output_len - (pred_len + pred_start) + snippet_pad\n",
    "    #  150ms. Aiming for the average distance.\n",
    "    pad_value_as_dist = 300 \n",
    "    pad_value = trainable.distfield_to_nn_output(torch.Tensor([pad_value_as_dist])).item()\n",
    "    dist = np.concatenate([\n",
    "        np.full(shape=(prefix_len,), fill_value=pad_value),\n",
    "        summed.numpy(),\n",
    "        np.full(shape=(suffix_len,), fill_value=pad_value),\n",
    "    ])\n",
    "    return dist\n",
    "\n",
    "def spike_prob(distfield):\n",
    "    upshift = 0.5\n",
    "    prob = torch.clamp(-distfield + upshift, min=0, max=3)\n",
    "    return prob\n",
    "\n",
    "def infer_spikes(dist, dist_threshold, grad_threshold):\n",
    "    dist = _blur(dist, sigma=10.0)\n",
    "    is_near_spike = (dist < dist_threshold)\n",
    "    grad = np.gradient(dist)\n",
    "    has_low_grad = (grad < grad_threshold)\n",
    "    has_positive_grad2 = np.gradient(grad) > 0.00\n",
    "    spikes = is_near_spike & has_low_grad & has_positive_grad2\n",
    "    return spikes\n",
    "\n",
    "def infer_spikes_via_spline(dist, dist_threshold, grad_threshold, smoothing=0):\n",
    "    #spline = scipy.interpolate.InterpolatedUnivariateSpline(x=xs,  y=dist, k=4)#s=smoothing)\n",
    "    downsample = 1\n",
    "    dist_ds = scipy.signal.decimate(dist, downsample)\n",
    "    xs = np.arange(len(dist_ds))\n",
    "    spline = scipy.interpolate.UnivariateSpline(x=xs,  y=dist_ds, k=4, s=smoothing)\n",
    "    roots_idxs = np.round(spline.derivative().roots()).astype(int)\n",
    "    grad2_at_roots = spline.derivative().derivative()(roots_idxs)\n",
    "    dist_at_roots = spline(roots_idxs)\n",
    "    minima_idxs = roots_idxs[np.logical_and(grad2_at_roots > 0, \n",
    "                                            dist_at_roots < dist_threshold)] * downsample\n",
    "    minima = np.zeros_like(dist)\n",
    "    minima[minima_idxs] = 1\n",
    "    return minima, spline\n",
    "    grad = spline.derivative(n=1)(xs)\n",
    "    grad2 = spline.derivative(n=2)(xs)\n",
    "    is_near_spike = (spline(xs) < dist_threshold)\n",
    "    is_near_local_extremum = (grad < grad_threshold)\n",
    "    is_min = (grad2 > 0)\n",
    "    spikes = is_near_spike & is_near_local_extremum & is_min\n",
    "    return spikes, spline\n",
    "\n",
    "def _blur(x, sigma):\n",
    "    return scipy.ndimage.gaussian_filter1d(x, sigma=sigma, axis=0, mode='constant', cval=0.0)\n",
    "\n",
    "\n",
    "\n",
    "def sta(trainable):\n",
    "    threshold = 0\n",
    "    pred_len = 200\n",
    "    pred_start = 100\n",
    "    snippet_pad = 600\n",
    "    print(f'len(test_ds): {len(trainable.test_ds)}')\n",
    "    print(len(trainable.test_ds) + 1000 + input_len)\n",
    "    assert len(trainable.test_ds)+1000+input_len-1 == len(trainable.test_ds.ds.recording.stimulus)\n",
    "    distfield = whole_distfield(trainable, pred_len, pred_start, snippet_pad)\n",
    "\n",
    "    # Predicted spikes.\n",
    "    pred_spikes, spline = infer_spikes_via_spline(distfield, dist_threshold=0.6, grad_threshold=0.2)\n",
    "    num_color_channels = 4\n",
    "    #Actual spikes\n",
    "    actual_spikes = trainable.test_ds.ds.recording.spikes[:,0]\n",
    "    \n",
    "    print_stats(pred=pred_spikes, actual=actual_spikes)\n",
    "    pred_spike_idxs = np.squeeze(np.nonzero(pred_spikes))\n",
    "    actual_spike_idxs = np.squeeze(np.nonzero(actual_spikes))\n",
    "    stim =  trainable.test_ds.ds.recording.stimulus\n",
    "    pred_spike_snippets = retinapy.mea.spike_snippets(stim, pred_spike_idxs, 1, 1, total_len=input_len+output_len, post_spike_len=output_len)\n",
    "    actual_spike_snippets = retinapy.mea.spike_snippets(stim, actual_spike_idxs, 1, 1, total_len=input_len+output_len, post_spike_len=output_len)\n",
    "    pred_kernel = np.mean(pred_spike_snippets, axis=0)\n",
    "    actual_kernel = np.mean(actual_spike_snippets, axis=0)\n",
    "    return pred_kernel, actual_kernel, distfield, pred_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447b3b1-4ebe-45e3-8650-8e5bfd172b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kernel, actual_kernel, distfield, pred_spikes = sta(trainable)\n",
    "pred_kernel_1ms = scipy.signal.decimate(pred_kernel, 2, axis=0)\n",
    "actual_kernel_1ms = scipy.signal.decimate(actual_kernel, 2, axis=0)\n",
    "kernel_pad_1ms = 200\n",
    "bin_duration_ms = 1.008"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e00749-9d89-4f92-9ed7-f08a26a82b25",
   "metadata": {},
   "source": [
    "### 1.1 Results (the kernel)\n",
    "The steps to calculate this kernel are:\n",
    "\n",
    "    1. Use pretrained model to generate a distance field for the whole training data snippet.\n",
    "    2. Try and guess the location of spikes based on the distance field created in 1. This is a very\n",
    "        rudimentary heuristic approach to estimating the maximum likelihood spikes.\n",
    "    3. Run the standard spike train analysis on the spikes from 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8e41d-edc1-45a4-86fa-c0863f4830d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_plot(pred_kernel_1ms, kernel_pad=kernel_pad_1ms, bin_duration_ms=bin_duration_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053ee50-1664-4462-a94c-942daacbedaa",
   "metadata": {},
   "source": [
    "### 1.2 True STA kernel (from recorded spikes)\n",
    "For comparison, here is the STA kernel calculated from recorded spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9672a0-aa85-4e57-bb29-47239bd7b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_plot(actual_kernel_1ms, kernel_pad=kernel_pad_1ms, bin_duration_ms=bin_duration_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d1f07-e3ae-4ba6-9b9d-30a383f928f6",
   "metadata": {},
   "source": [
    "### 1.3 Spike inference. Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e7fa7-00ac-42b8-af8b-ca1e4c76f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _debug_spike_inference(pred_distfield, actual_distfield, start_ms=0, duration_ms=2000):\n",
    "    downsample = 2\n",
    "    pred_spikes, spline = infer_spikes_via_spline(pred_distfield, dist_threshold=0.2, \n",
    "                                                  grad_threshold=0.1)\n",
    "    xs_double_res = np.arange(duration_ms*downsample) + start_ms*downsample\n",
    "    xs = np.arange(duration_ms) + start_ms\n",
    "    spline_1ms = scipy.signal.decimate(spline(xs_double_res), downsample)\n",
    "    pred_df_1ms = scipy.signal.decimate(pred_distfield, downsample, axis=0)\n",
    "    actual_df_1ms = scipy.signal.decimate(actual_distfield, downsample, axis=0)\n",
    "    spike_idxs = np.round(np.squeeze(np.nonzero(pred_spikes)).astype(float) / downsample)\n",
    "    scatter_p = go.Scatter(x=xs, y=pred_df_1ms[start_ms:start_ms+duration_ms], \n",
    "                          name=\"Pred log(distfield/20)\")\n",
    "    scatter_y = go.Scatter(x=xs, y=actual_df_1ms[start_ms:start_ms+duration_ms],\n",
    "                          name=\"Actual log(distfield/20)\")\n",
    "    scatter_s = go.Scatter(x=xs, y=spline_1ms,\n",
    "                           name=\"Spline approx\")\n",
    "    fig = subplots.make_subplots(rows=3, cols=1, shared_xaxes=True) \n",
    "    fig.add_trace(scatter_p, row=1, col=1)\n",
    "    fig.add_trace(scatter_y, row=2, col=1)\n",
    "    fig.add_trace(scatter_s, row=3, col=1)\n",
    "    fig.update_layout({\n",
    "        \"height\": 600,\n",
    "        \"width\": 800})\n",
    "    spikes_in_xs = spike_idxs[np.logical_and(spike_idxs > start_ms, spike_idxs < start_ms + duration_ms)]\n",
    "    #spikes_in_xs = np.squeeze(np.nonzero(pred_spikes[start_ms:start_ms+duration_ms])) + start_ms\n",
    "    print(len(spikes_in_xs))\n",
    "    if len(spikes_in_xs) < 100:\n",
    "        for s in spikes_in_xs:\n",
    "            fig.add_vline(x=s, line_width=0.8, line_dash='dot', line_color='grey', row=1, col=1)\n",
    "    fig.show()\n",
    "\n",
    "def debug_spike_inference(trainable, start_ms):\n",
    "    pred_len = 200\n",
    "    pred_start = 100\n",
    "    snippet_pad = 600\n",
    "    pred_distfield = whole_distfield(trainable, pred_len, pred_start, snippet_pad)\n",
    "    max_dist = 600\n",
    "    actual_distfield = sdf.distance_field(trainable.test_ds.ds.recording.spikes[:,0], max_dist)\n",
    "    actual_distfield = trainable.distfield_to_nn_output(torch.Tensor(actual_distfield)).numpy()\n",
    "    _debug_spike_inference(pred_distfield, actual_distfield, start_ms)\n",
    "    \n",
    "debug_spike_inference(trainable, start_ms=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a02bc-2133-4db6-a8bf-68e4fac95234",
   "metadata": {},
   "source": [
    "## 2. Kernel vias optimized input\n",
    "Calculate the pseudo kernel by optimizing the input stimulus for a given model output.\n",
    "\n",
    "Some inspiration for the training loop came from: https://github.com/utkuozbulak/pytorch-cnn-visualizations/blob/master/src/cnn_layer_visualization.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62ffff-1bf4-4671-966f-00401fbcce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = pd.DataFrame({\n",
    "    'names':['Red', 'Green', 'UV', 'Blue', 'Stim'],\n",
    "    'display_hex':['#ff0a0a', '#0aff0a', '#0a0aff', '#303030', '#0a0a0a']})\n",
    "\n",
    "def kernel_plot(kernel, snippet_pad, bin_duration_ms):\n",
    "    fig = go.Figure()\n",
    "    xs = (np.arange(kernel.shape[0]) - kernel.shape[0]) * bin_duration_ms\n",
    "    # Shift the x-axis to have zero in the middle.\n",
    "    xs += snippet_pad\n",
    "    #fig.add_vline(x=-100, line_width=2, line_dash='dot', line_color='grey',\n",
    "    #              annotation_text='-100ms', annotation_position='bottom right')\n",
    "    for c in range(4):\n",
    "        fig.add_trace(go.Scatter(x=xs, \n",
    "                                 y=kernel[:,c], \n",
    "                                 line_color=colormap.loc[c]['display_hex'], \n",
    "                                 mode='lines'))\n",
    "    fig.update_layout(autosize=False,\n",
    "                      height=400,\n",
    "                      width=800,\n",
    "                      margin=dict(l=1, r=1, b=1, t=25, pad=1),\n",
    "                      yaxis_fixedrange=True,\n",
    "                      showlegend=False,\n",
    "                      title='Kernel',\n",
    "                      title_x=0.5,\n",
    "                      title_pad=dict(l=1, r=1, b=10, t=1),\n",
    "                      xaxis={'title':'time (ms), with spike at 0'},\n",
    "                      yaxis={'title':'Stimulus', 'range': [-2,3]} )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def display_dist(model_out, y, downsample=2, loss_slice=None):\n",
    "    y = scipy.signal.decimate(y, downsample)\n",
    "    model_out = scipy.signal.decimate(model_out, downsample)\n",
    "    xs = np.arange(len(y))\n",
    "    fig = go.Figure()\n",
    "    scatter_model = go.Scatter(x=xs, y=model_out, name='Pred', line_color='gray')\n",
    "    fig.add_trace(scatter_model)\n",
    "    scatter_y = go.Scatter(x=xs, y=y, name='Actual', line_color='red')\n",
    "    fig.add_trace(scatter_y)\n",
    "    if loss_slice:\n",
    "        fig.add_vline(x=loss_slice.start//downsample, line_width=0.8, \n",
    "                      line_dash='dot', line_color='grey', row=1, col=1)\n",
    "        fig.add_vline(x=loss_slice.stop//downsample, line_width=0.8, \n",
    "                      line_dash='dot', line_color='grey', row=1, col=1)\n",
    "    fig.update_layout(height=400,\n",
    "                      width=800,\n",
    "                      title='Log distance field. Model (gray), actual (red)')\n",
    "    return fig\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "def calc_kernel(trainable, num_steps=10, \n",
    "                spikes=None,\n",
    "                loss_slice=None,\n",
    "                mag_weight=0.01, freq_weight=0.01, cutoff_freq=None):\n",
    "    trainable.model.eval()\n",
    "    num_shifts = 5\n",
    "    base_len =  trainable.test_ds[0][0].shape[1] # 3574\n",
    "    color_channels = 4\n",
    "    total_stim_len = base_len + num_shifts\n",
    "    input_stim = torch.normal(mean=0, std=2, size=(color_channels, total_stim_len), requires_grad=True, dtype=torch.float32, device='cuda')\n",
    "    device = input_stim.device\n",
    "    assert input_stim.shape[1] == base_len + num_shifts\n",
    "    # Set the spike channel to zero.\n",
    "    spike_history = torch.zeros(size=(1, total_stim_len), \n",
    "                                #requires_grad=True, \n",
    "                                device=device)\n",
    "    spike_history[0, 3174:-1] = trainable.test_ds.MASK_VALUE\n",
    "    # We can't enable grad before the stack, as it will be copied.\n",
    "    # see: https://discuss.pytorch.org/t/variable-update-after-autograd-in-torch-cat-torch-vstack-nn-zeropad2d-torch-index-select-and-torch-roll/124823\n",
    "    #input_stim = input_snippet[0,0:5,:]\n",
    "    #input_stim.requires_grad_(True)\n",
    "    optimizer = torch.optim.Adam([input_stim], lr=0.005, weight_decay=0)\n",
    "    \n",
    "    # Frequency reg.\n",
    "    freq_bins = torch.fft.rfftfreq(total_stim_len, d=1/2231.596)\n",
    "    #torch.zeros_like(freq_bins, device=device)\n",
    "    if cutoff_freq:\n",
    "        freq_penalty = torch.zeros_like(freq_bins, device=device)\n",
    "        freq_penalty[torch.where(freq_bins > cutoff_freq)] = freq_weight\n",
    "    else:\n",
    "        freq_penalty = torch.arange(len(freq_bins), device=device)/len(freq_bins)\n",
    "    \n",
    "    \n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    def target_nn_output(spike_indicies, shift, length=400):\n",
    "        spikes = np.zeros((length,))\n",
    "        spikes[spike_indicies+shift] = 1\n",
    "        df = retinapy.spikedistancefield.distance_field(spikes, default_distance=600)\n",
    "        res = trainable.distfield_to_nn_output(torch.Tensor(df))\n",
    "        res = torch.unsqueeze(res, 0).cuda()\n",
    "        return res\n",
    "    \n",
    "    # Precompute the targets, as they don't change.\n",
    "    targets = [target_nn_output(np.array(spikes), shift=-d, length=400) for d in range(num_shifts)]\n",
    "    targets = torch.vstack(targets)\n",
    "    for i in range(0, num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        input_snippet = torch.stack(\n",
    "            [torch.vstack([input_stim, torch.abs(spike_history)])[:,start:start+base_len] for start in range(num_shifts)])\n",
    "        model_out = trainable.model(input_snippet)\n",
    "        model_loss = torch.sum(torch.norm((model_out - targets)[:,loss_slice], p=2, dim=1))\n",
    "        loss = model_loss\n",
    "        mag_loss = mag_weight * torch.sum(torch.norm(input_stim, p=1, dim=1))\n",
    "        freq_loss = torch.norm(torch.fft.rfft(input_stim) * freq_penalty)\n",
    "        #spike_loss = torch.sum(torch.abs(spike_history))\n",
    "        #loss += spike_loss\n",
    "        loss += mag_loss \n",
    "        loss += freq_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f'Loss. mag: {mag_loss}, freq: {freq_loss}, model: {model_loss}')\n",
    "    res = input_stim[:,0:base_len].detach().cpu().numpy().T\n",
    "    return res, targets.cpu(), input_snippet.detach()\n",
    "\n",
    "def smooth(stimulus):\n",
    "    # Bins are 0.5ms = 2000\n",
    "    fs = 2000\n",
    "    nyq = 0.5 * fs\n",
    "    cutoff = 30\n",
    "    b, a = scipy.signal.butter(3, cutoff/nyq)\n",
    "    s = scipy.signal.filtfilt(b, a, stimulus, axis=0, method='gust')\n",
    "    return s\n",
    "    \n",
    "def smooth_bl(stimulus):\n",
    "    stimulus_ = np.expand_dims(stimulus,0)\n",
    "    stimulus[:,0:3] = cv.bilateralFilter(stimulus_[:,:,0:3], d=0, sigmaColor=1, sigmaSpace=100)\n",
    "    res = stimulus\n",
    "    res[:,3] = 0\n",
    "    return res\n",
    "\n",
    "def blur(stimulus, sigma=10.0):\n",
    "    return scipy.ndimage.gaussian_filter1d(stimulus, sigma=sigma, axis=0, mode='constant', cval=0.0)\n",
    "\n",
    "def calc_and_display_opt_input():\n",
    "    k, targets, last_inputs = calc_kernel(trainable, num_steps=1000)\n",
    "    k_1ms = scipy.signal.decimate(k, 2, axis=0)\n",
    "    #k_1ms = smooth(k)\n",
    "    smooth_k = k_1ms\n",
    "    smooth_k = blur(k_1ms)\n",
    "\n",
    "    # 3574 (3174 + 400)\n",
    "    fig = kernel_plot2(smooth_k, snippet_pad=400//2, bin_duration_ms=1.008)\n",
    "    fig.show()\n",
    "    model_out = trainable.model(last_inputs).detach().cpu().numpy()\n",
    "    #fig = display_dist(model_out[0], targets[0].cpu().numpy())\n",
    "    #fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f9d73-9770-4a36-823e-53670a7874c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 3\n",
    "ks = []\n",
    "for t in range(num_trials):\n",
    "    downsample = 2\n",
    "    spikes = np.array([5, 10, 15, 20])*downsample\n",
    "    loss_slice=slice(0*downsample, 50*downsample)\n",
    "    \n",
    "    k, targets, last_inputs = calc_kernel(trainable, \n",
    "                                          num_steps=5000,\n",
    "                                          spikes=spikes,\n",
    "                                          loss_slice=loss_slice,\n",
    "                                          mag_weight=0.001,\n",
    "                                          freq_weight=0.02,\n",
    "                                          cutoff_freq=40)\n",
    "    \n",
    "    k_1ms = scipy.signal.decimate(k, 2, axis=0)\n",
    "    ks.append(k_1ms)\n",
    "    fig = kernel_plot(k_1ms, snippet_pad=400//2, bin_duration_ms=1.008)\n",
    "    fig.show()\n",
    "    model_out = trainable.model(last_inputs).detach().cpu().numpy()\n",
    "    fig = display_dist(model_out[0], targets[0].cpu().numpy(), loss_slice=loss_slice, downsample=2)\n",
    "    fig.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cc3db-33bb-4735-bbb6-78f561fc6246",
   "metadata": {},
   "source": [
    "## Smoothed kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86b168-e70d-49cb-bc81-9edd08d87680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ks:\n",
    "    fig = kernel_plot(blur(k, sigma=10), snippet_pad=200, bin_duration_ms=1.008)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768d62d-950c-4c15-8ea7-7f698b12d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ef159-ab21-4834-b8f3-2458ee7488bf",
   "metadata": {},
   "source": [
    "## Cluster 21 STA kernel\n",
    "![Cluster 21 kernel](resources/cluster21_kernel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205d7149-58c4-4a5a-827f-3e2affb51894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95130595-3a3a-4649-a07b-8e3595122240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
